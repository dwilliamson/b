<<Reflection in C++, Part 3: On IDL Compilers and Template Meta-Programming>>

I'm going to take a walk to the distant past in this post, recalling the implementation that resulted from my discovery of reflection as a concept in computer languages. I saw the need for a "property" API in the game we were writing at the time and thought I saw huge benefits to generalising it.

After experimenting at home for a few weeks, I got to work on what was probably my most over-engineered library ever. This was some time in 2003 and the platform was the Sony PSP with GCC version 3.1. While GCC was leading the way in terms of template support, console vendors were always a few releases behind and MSVC support 
 - the days before compiler template support became somewhat dependable.
 
Between writing other major parts of our engine and game code, leading the team and running the schedule, the implementation took some 3 months in total. Quite a difference from Splinter Cell! It was a lot of fun developing but could have been a lot simpler - I learned a lot of lessons about over-complexity in C++ APIs while expecting other people to use it.


== An overview ==

As seen from part 2 in the series, manual registration of reflection data can be error-prone and an extra responsibility to maintain. Depending upon your situation, this may or may not be acceptable. There are lots of ways, using increasing template complexity and macros to automate a lot of this, but some form of manual registration will always remain.

There are few options available to get around this:

* Use a tool that can parse your C++ code and automatically deduce the reflection data. A good example of this is {clReflect|http://donw.org/b/?d=clReflect}, which will be discussed in a later post. A more recognisable example is {SWIG|http://www.swig.org/}, which can parse your C++ APIs and write code such that other languages can interoperate with them. Parsing C++ is a non-trivial problem and there are many 3rd party tools out there that can take this burden for you. You can sometimes make a compromise whereby you write a very primitive parser that knows only how to parse macro-marked lines in a file.
* Derive the data from debug information generated by your compiler. This is a highly platform-specific method that won't necessarily give you the complete picture. PDB files are a good example of this but the API can change any minute and break your tools. The internals are undocumented and provide no guarantees as to the performance of any specific method of querying its data. However, it can be a very powerful and transparent means of generating reflection data.
* Write your interfaces in a language that already supports reflection, such as Python or C#. It's then trivial to write tools in that language that generate C++ reflection registration code when the game runs. Naughty Dog use a dialect of LISP (Scheme) to achieve this for them. You will have issues mapping some of the language constructs to C++ but it's a very low cost means of solving the problem in a cross-platform manner. --THIS COULD ALSO BE A DATA FILE--
* Write your interfaces in a data language, such as JSON or XML and use whatever language you please to parse that and output generated C++ code for reflection registration.
* Write all your interfaces in a simpler language that you can write a parser for, typically called an Interface Definition Language (IDL). This is used as a replacement for your C++ header files, which are automatically generated, along with registration code.

The debug info method will be covered in a later post but the remaining methods can output either generated C++ code or data files that describe your reflection data. Data files are a nice compact way to store the reflection information but generated code provides an easy way to assign class offsets to fields and memory addresses to functions. Without generated code, you need to determine:

* How are class offsets found? There are various ways of achieving this, including writing code that figures out the offsets yourself for your target ABI. Alternatively, you can go via the slower route of using a dictionary which you need to query at runtime by variable name to access field data.
* How are function addresses found? You can look at the debug information output by your compiler or inspect MAP files.

There are many combinations the above that can be used with success but I ultimately went with a custom IDL with its own compiler. The specific functionality was:

* All interfaces were edited in a language similar to the {COM IDL|http://msdn.microsoft.com/en-us/library/windows/desktop/aa378712(v=vs.85).aspx}.
* A compiler would parse the IDL files and output equivalent C++ header files and registration code for the game.
* The compiler would also output XML files which the level editor would use to edit/serialise objects.
* The C++ registration code was used directly to register the APIs of 3rd party libraries.
* C++ game code would need to derive from the types in the generated header files and implement their interfaces.

Reflection support was extensive, featuring:

* Namespaces.
* Enumerations.
* POD structures and interfaces.
* Fields and properties (as pairs of Get/Set functions).
* Functions and class methods.
* Events.


== The Interface Definition Language ==

Except for very low-level engine libraries, C++ header files were never manually edited. Instead, we used IDL files which looked like:

[code]
// List of relative paths to other IDL files that contain dependent types
import "DependentFileA.idl";
import "DependentFileB.idl";

// A module was equivalent to a C++ namespace
module example
{
	// The IDL compiler would output generated C++ headers files and associated
	// reflection registration cpp files when encountering this statement.
	// In this case, "ReflectExample.h" and "ReflectExample.cpp"
	reflect ReflectExample;
	
	// Forward-declaration of low-level library types, with the header files
	// which would get auto-included in the generated header files when you use them.
	// This technique was also used to forward-declare types introduced by 3rd
	// party libraries used.
	class Vector3
		[header_file("maths/Vector.h")];
	class String
		[header_file("base/String.h")];
	
	// Generate C++ enumeration with a basic expression evaluator for enum values
	enum Enumeration
	{
		ENUM_A,
		ENUM_B = 2,
		ENUM_C = 3 * 5
	}
	
	// These generated C++ structures that contained only data members
	// Only single, public inheritance was supported
	struct DataStructure : Base
	{
		float x, y, z;
		int a, b, c;
		Vector3 v;
		
		// Data members could have default initialisation values
		int w = 4;
	}
	
	// The majority of types were interfaces, represented in C++ as abstract base classes
	interface Interface : BaseInterface
	{
		// These compiler to pure virtual functions which required later implementation
		void BasicMethod();
		bool ParamMethod(int a, const PODStructure* b, const Vector3& v) const;
		
		// As interfaces were abstract base classes, storage of data members was not supported.
		// A property was used instead. These get compiled to a pair of pure virtual Get/Set
		// methods.
		// Read-only properties had only Get methods.
		property int IntProp;
		property void* SomePtr [lit][transient][/lit];
		property DataStructure StructProp [lit][some_attribute("a", "b"), other_attribute][/lit];
		property readonly int CantChange;
		
		// Templates weren't supported in the IDL but if you knew all the parameters to
		// an instantiation of a container template, you could reference them.
		// I can't recall if this was added late or planned like this because a more generic
		// solution would have been to allow referencing of templated types and use properties
		// instead.
		// These would compile to Get methods, returning non-const references so that the
		// containers could be read or changed.
		container list<int> AList;
		container vector<DataStructure> AVector [lit][attribute][/lit];
		
		// Events were dispatchers of events that listeners could register their interest in.
		// You specified the event in the IDL, along with its parameters, allowing external
		// scripts or tools to use data-driven event management.
		event SomeEvent(int a, float b);
	}
	
	extend?
}
[/code]

Some of the steps above have been removed to aid brevity and consistency with other parts of this series. However, there were some tricky implementation details that would trip people up regularly (such as our dependence on a custom COM implementation) and this part will be better served ignoring them.

Note the use of attributes above in square brackets; a good example of being able to take advantage of the custom design in your language to make things a little easier. The forward declaration also took the opportunity to define its own attribute, --header_file--, to pull in low-level or 3rd party API types. Attributes in this case were string keys mapped to arrays of string values.


== The Generated Source Code ==

If the IDL compiler encountered a --reflect-- statement it would output a header file that looked like:

[code]
// Implied from the import names
#include "DependentFile.h"
#include "DependentFile.h"

// A result of a forward declaration with the "header_file" attribute
#include "maths/Vector.h"
#include "core/String.h"

namespace example
{
	enum Enumeration
	{
		ENUM_A,
		ENUM_B = 2,
		
		// Result has been calculated by the expression evaluator so that the IDL compiler could detect
		// expression errors, instead of passing it onto the header file and letting the C++ compiler
		// deal with it.
		ENUM_C = 15
	}
	
	struct DataStructure : public Base
	{
		// Automatic constructor generated with default initialisation for the
		// required data members
		DataStructure() : w(4)
		{
		}
		
		float x, y, z;
		int a, b, c;
		Vector3 v;
		
		int w;
	}
	
	// In reality this class spec was unfortunately not this simple but this should
	// highlight the intent. This is an abstract base class with nothing but pure virtuals. 
	class Interface : public BaseInterface
	{
		// Pure virtuals for each defined method
		virtual void BasicMethod() = 0;
		virtual bool ParamMethod(int a, const PODStructure* b, const Vector3& v) const = 0;
		
		// Get/Set pairs for each property
		virtual int GetIntProp() const = 0;
		virtual void SetIntProp(int v) = 0;
		virtual void* GetSomePtr() const = 0;
		virtual void SetSomePtr(void* v) = 0;
		virtual const DataStructure& GetStructProp() const = 0;
		virtual void SetStructProp(const DataStructure& v) = 0;
		
		// Only a Get method for the read-only property
		virtual int GetCantChange() = 0;
		
		// Accessors for the containers
		virtual std::list<int>& GetAList() = 0;
		virtual std::vector<DataStructure>& GetAVector() = 0;
		
		// Accessors for typed event dispatchers
		typedef EventDispatcher<int, float> Event_SomeEvent;
		virtual Event_SomeEvent& GetEvent_SomeEvent() = 0;
	}
}
[/code]

It would also output a C++ source file that contained code to register the primitives with the reflection database when the game started:

[code]
#include "ReflectExample.h"

void ReflectExample(Database& db)
{
	// Use of the Named Parameter Idiom to chain operations together
	db

	// Primitive()/End() pairs used a stack to push and pop primitive scope
	// Added primitives would inspect the stack for a parent to attach to
	.Module("example")

		// Use of a "type-safe" variable argument type to preallocate the required data and populate it
		// with name/value pairs
		.Enum("Enumeration", VarArgs(3)
			("ENUM_A", example::ENUM_A)
			("ENUM_B", example::ENUM_B)
			("ENUM_C", example::ENUM_C)
		)
		.Class<example::DataStructure, example::Base>()
			.DataMember("x", &example::DataStructure::x)
			.DataMember("y", &example::DataStructure::y)
			.DataMember("z", &example::DataStructure::z)
			.DataMember("a", &example::DataStructure::a)
			.DataMember("b", &example::DataStructure::b)
			.DataMember("c", &example::DataStructure::c)
			.DataMember("v", &example::DataStructure::v)
			.DataMember("w", &example::DataStructure::w)
		.End()
		.Interface<example::Interface, example::BaseInterface>
			.Method("BasicMethod", &example::Interface::BasicMethod)
			.Method("ParamMethod", &example::Interface::ParamMethod)
			.Property("IntProp", &example::Interface::GetIntProp, &example::Interface::SetIntProp)

			// Attributes would attach last known primitive
			.Property("SomePtr", &example::Interface::GetSomePtr, &example::Interface::SetSomePtr)
				.Attribute("transient")

			// Multiple attributes would would attach to the same last known primitive
			.Property("StructProp", &example::Interface::GetStructProp, &example::Interface::SetStructProp)
				.Attribute("some_attribute", VarArgs(2)("a")("b"))
				.Attribute("other_attribute")

			.Property("CantChange", &example::Interface::GetCantChange)

			// MakeList and MakeVector return allocated container interfaces which the type would own
			.Container("AList", MakeList(&example::Interface::GetAList))
			.Container("AVector", MakeVector(&example::Interface::GetAVector))
				.Attribute("some_attribute")

			.Event("SomeEvent", &example::Interface::GetEvent_SomeEvent)
		.End()
	.End();
}

[/code]

This is certainly prettier than the Splinter Cell solution but the basics are very similar. However, there is an awful lot more going on, especially the method registration code which could figure out the parameters of any function you passed to it. One might be tempted to question why, if the IDL compiler knew everything about the types it was defining, the registration code used such complicated template programming to figure it all out again? For example, data members could have been:

[code]
	.DataMember("x", "int", is_value, is_not_const, offsetof(example::DataStructure, x))
[/code]

This would have cut down on the generated code size, made the C++ reflection API simpler and brought down compile-times. However, I wanted to avoid this for two reasons:

* It would make manual reflection of types with 3rd party APIs quite painful/tricky.
* For redundancy reasons, I wanted to be able to define any types without having to depend on the success of the IDL compiler as a concept.

With an IDL compiler in place, I no longer see these has valid points to be worried about and favour the importance of simplicity and efficiency over genericity. In fact, I see the second reason as entirely without merit. It's a classic example of over-design in the absence of experience - you never know how many projects or companies may end up using your fancy new engine, right?


== The Generated Data Description ==

The final file output by the IDL compiler was an XML description of the types in the file:

[code]
<types>
	<module name="example">
		<enum name="Enumeration">
			<const name="ENUM_A" value="0" />
			<const name="ENUM_B" value="2" />
			<const name="ENUM_C" value="15" />
		</enum>
		<struct name="DataStructure" base="example::Base">
			<data type="float" name="x" />
			<data type="float" name="y" />
			<data type="float" name="z" />
			<data type="int" name="a" />
			<data type="int" name="b" />
			<data type="int" name="c" />
			<data type="Vector3" name="w" />
		</struct>
		<interface name="Interface" base="example::BaseInterface">
			<method name="BasicMethod" />
			<method name="ParamMethod" return="bool" is_const="true">
				<param type="int" name="a" />
				<param type="PODStructure" is_const="true" is_pointer="true" name="b" />
				<param type="Vector3" is_const="true" is_reference="true" name="v" />
			</method>
			<property type="int" name="IntProp" />
			<property type="void" is_pointer="true" name="SomePtr">
				<attribute name="transient" />
			</property>
			<property type="DataStructure" is_reference="true" is_const="true" name="StructProp">
				<attribute name="some_attribute">
					<value content="a" />
					<value content="b" />
				</attribute>
				<attribute name="other_attribute" />
			</property>
			<property type="int" is_readonly="true" name="CantChange" />
			<container type="list" name="AList">
				<param type="int" />
			</container>
			<container type="vector" name="AVector">
				<param type="DataStructure" />
				<attribute name="attribute" />
			</container>
			<event name="SomeEvent">
				<param type="int" name="a" />
				<param type="float" name="b" />
			</event>
		</interface>
	</module>
</types>
[/code]

This could have actually been used at runtime to populate the reflection database. In fact, it demonstrates the amount of knowledge the IDL compiler had of the files it compiled. However, two parts of the puzzle it didn't know about were data member offsets and function addresses, so some form of generated code may have been required to register these (or alternatively, the techniques discussed earlier could have been used). Additionally, there is a significant amount of template code for function parameter passing and container management that would need alternatives. The roots go deep. I will discuss these alternatives in detail in later posts.

The primary purpose of this file was to drive the game level editor, which was embedded in Lightwave. Properties and data members were used to populate the property editor user interface with strings, values, sliders and colour pickers, etc. The level editor would also automatically draw bounding volumes and other helpful elements in the 3D view of Lightwave that could be manipulated if it found an object containing those fields.

The implementation was simply a collection of named objects in memory, each containing a dictionary mapping field names to field values. These objects were saved to disk as a complete level using the XML description of each type output by the IDL compiler.

At runtime, there was a "hot-loading" connection between Lightwave and the game. If the game detected a change to the level input file it would re-parse it looking for new/deleted objects or modified fields and update the running game with the changes without reloading the entire level. Due to the entire pipeline being XML-based, turn-around was a few seconds on each change, which was never ideal - this is one clear advantage the Splinter Cell implementation had over this with its realtime network updates.


== The Responsibility of the Programmer ==

So after all the C++ files have been generated, they need to be implemented. I wanted the users to be able to add their own private data types and methods to classes without having to stretch the power of the IDL parser such that it could parse all possible C++ type information. I also didn't want to mix generated code with code the programmer would edit. To achieve that, it required the programmer create an implementation of any interfaces:

[code]
class InterfaceImpl : public Interface
{
public:
	// Method implementations
	void BasicMethod() { }
	bool ParamMethod(int a, const PODStructure* b, const Vector3& v) const { }

	// Property implementations
	int GetIntProp() const { return m_IntProp; }
	void SetIntProp(int v) { m_IntProp = v; }
	void* GetSomePtr() const { return m_SomePtr; }
	void SetSomePtr(void* v) { m_SomePtr = v; }
	const DataStructure& GetStructProp() const { return m_StructProp; }
	void SetStructProp(const DataStructure& v) { m_StructProp = v; }
	int GetCantChange() const { return m_CantChange; }

	// Container accessors
	std::list<int>& GetAList() { return m_AList; }
	std::vector<DataStructure>& GetAVector() { return m_AVector; }

	// Event accessors
	Event_SomeEvent& GetEvent_SomeEvent() { return m_SomeEvent; }

private:
	// Definitions of data declared publically in the IDL
	int m_IntProp;
	void* m_SomePtr;
	DataStructure m_StructProp;
	int m_CantChange;
	std::list<int> m_AList;
	std::vector<DataStructure> m_AVector;
	Event_SomeEvent& m_SomeEvent;
};
[/code]

This was effectively an automatic implementation hiding system where classes communicated with each other via interfaces. You could also do arbitrary things when properties were accessed, e.g. a Filename property would kick off a file system load when it was set.


== A Critical Retrospective and Comparison with Unreal ==

The use of virtuals here was pretty crazy, especially on the PSP. We started moving interface implementations from source files into header files so that some of the more performance-sensitive types could access each other directly. This meant, for every interface, you would get:

* Interface.idl
* Interface.h (generated)
* InterfaceImpl.h
* InterfaceImpl.cpp

This caused a lot of boiler-plate, requiring you to effectively type your interfaces 3 times. After a while during development, a pattern emerged whereby any common fields you wanted to access in an object were added to a public structure property that you could access with one call:

[code]
interface Interface
{
	struct DataType
	{
		int x, y, z;
		string some_string;
		Vector vec;	
	};

	property DataType Data;
}
[/code]

This reduced boiler-plate, increased performance and made the code easier to read.

This was all caused by many reasons, including:

* I didn't want to emit header files that the programmer could augment with their own private data and functions. This would require that the IDL compiler keep track of regions it could modify and would require source control interaction (this was before the days of Git and Mercurial; we used Perforce with a check-out model). The generated header files were not checked in to source control.
* I didn't want to violate the {Abstract Base Class|http://www.parashift.com/c++-faq-lite/abcs.html} concept.
* I wanted to avoid making a hugely complicated IDL parser that would need to parse C++ equivalent constructs.

To be fair to my younger self, the last point is a very valid one. The IDL concept is very neat but its main problem is that C++ is a very complicated language. Trying to express a C++ interface in an IDL means you have to make the IDL just as expressive, representing a significant investment in an IDL compiler. Given a big game's heavy dependence on 3rd party libraries, you will always need some way of integrating them. There will always be corner cases of the C++ language that you'll be required to adjust to, especially when your programming team is large (e.g. 30-50 people).

The UnrealScript solution to this is actually quite cute. When I was a younger, more aggressive and idealistic programmer, I would have attributed the solution to a failure to implement UnrealScript properly and account for all possibilities:

[code]
structcpptext
{
	// insert edge case C++ code you didn't account for here
	// or, if you like, an inline function!
	// also feel free to insert any of your private data and functions here
	// while they'll be visible publically, they won't be accessible to the reflection api
}
[/code]

In terms of return on investment, {structcpptext|http://wiki.beyondunreal.com/Structs} is genius. Of course, no metadata exists for anything within a cpptext block but the solution can handle any C++ construct and allows you to generate C++ header files which never need to be modified.

Before I cover the details of the C++ reflection API implementation, I want to warn that it was very complicated. Not many people could approach the code and modify it with confidence that they hadn't broken anything (or indeed, if they'd even achieved the task they'd set out to achieve in the first place). It generated an immense amount of code at compile-time that increased the executable size on a platform where memory was scant. The contribution to compile-times and maintainence across compilers on multiple platforms was not ideal.

Unreal doesn't have a very friendly or obvious runtime reflection modification API: it's very simple and bare-bones. This has been evident many times in the past when I've seen programmers recreate much of Unreal's functionality to achieve their goals without knowing about the options available to them. However, I don't think this is a bad thing. On the contrary, it was superior to my approach because it didn't spread engineer effort maintaining two complicated systems.

Another missing feature was a pre-processor. While I'm sure back in my more energetic days I'd endeavour to write one myself, it's quite simply not a task that should be let anywhere near your game schedule. {Boost.Wave|http://www.boost.org/doc/libs/1_48_0/libs/wave/index.html} is a bullet-proof preprocessor that can either be embedded in your compiler or, preferably, chained with the {Wave Driver|http://www.boost.org/doc/libs/1_48_0/libs/wave/doc/wave_driver.html} from the command-line. To convince yourself, an older version is still available in {pre-compiled form|http://www.codeproject.com/Articles/3853/Wave-a-Standard-conformant-C-preprocessor-library} for you to play with. I've used Wave implementing there different shader permutation build engines and in each case it has performed admirably.

If I was to rework this particular implementation, I would:

* Use Unreal's --structcpptext-- solution.
* Ditch all use of virtuals with their inheritance requirements, requiring the programmer to only implement the IDL.
* Output reflection data as a simple binary format that gets loaded at runtime, eliminating the complex template API.
* Use {MAP files|http://msdn.microsoft.com/en-us/library/k7xkk3e2(v=vs.80).aspx} to get function addresses (to be discussed in a later part).
* Generate code that only maps field names (as hashes) to their offsets.


== The Data Definition Language ==

A much simpler way of approaching this challenge is to make your IDL compiler less integral to your method of programming. This turns the language into more of a Data Definition Language (DDL) where you ensure that the DDL compiler only generates simple data structures involved in data transactions between systems that manipulate external state. All the DDL compiler will be doing is writing simple header files with no implementation requirements. For example, if you're writing an entity/component system, you can implement components as pure data structures that get edited in your DDL compiler. These generate reflection information and header files that can be used by your source. You then write external systems that can send and receive these components as part of their update:

[code]
// Components.ddl --> Generates Components.h
type Wheel
{
	RigidBody* chassis;
	float tire_radius;
	float tire_extent;
	float suspension_rest_length;
	float suspension_damping_relax;
	// etc...
}

// Physics.cpp
void UpdateWheels(const std::vector<Wheel>& wheels)
{
	for (size_t i = 0; i < wheels.size(); i+)
	{
		Wheel& wheel = wheels[i];
		// update code for wheel
	}
}
[/code]

This is a paradigm shift that a lot of developers will be in the process of going through already, adapting to the requirements of multi-processor systems with non-coherent local memory stores. Of course, you lose the language binding benefits of reflection, but you may have other solutions to that will make up for it.


== Writing a Parser ==

Writing parsers is quite fun; writing compilers and virtual machines, even more so. However, in order to write an IDL parser, you will only need to touch a fraction of the theory. There's no need for a back-end implementation as you're essentially writing a source-to-source converter. The back-end of a compiler usually covers code generation, optimisation and complex analysis of the source, and can be an amazingly complex branch of compiler development.

The front-end of an IDL compiler covers three distinct steps:

* The Lexer performs lexical analysis on an input character stream, converting a series of bytes into Tokens. A token can be a descriptive representation of a keyword, string sequence, language operator, number or other symbol. The main goal is to abstract away the character stream so that the next step can work in
* The Parser takes the output

If this is something that interests you, you can learn a lot by designing a very simple VM with move, call and arithmetic instructions, and writing an assembler for it. At that point, the translation from parsed instruction to emitted instruction is 1-to-1, giving a nice gentle introduction to the entire process.

USE DDL

* C++ is a very complicated language and trying to define interfaces 

With data files, method addresses are unobtainable unless you combine with MAP files.

== Data members, enums, varargs ==

reference specialisation
offsetoff template

STUFF
Unreal cpptext
No derivation from base object; it was prefixed
address of virtual
Jack Crenshaw
Dragon book
You always need a solution for integration of 3rd party libraries
PostLoad function! (is-a vs. has-a relationship)
offsetof fix
inline functions with IDL files
Events as resources to be bound to at runtime
Hot-loading of the entire level from within Lightwave
Lua binding